{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "import os\n",
    "import functools\n",
    "import re\n",
    "import pprint as pp\n",
    "import datetime\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "import fitgrid\n",
    "import fitgrid.utils as fgutil\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from udck19_utils import (\n",
    "    formula_to_name,\n",
    "    plotchans,\n",
    "    MPL_32_CHAN, \n",
    "    MPL_MIDLINE,\n",
    "    read_fg_summaries_hdf,\n",
    "    panel_from_idx\n",
    ")\n",
    "\n",
    "\n",
    "from udck19_filenames import (\n",
    "    EEG_EPOCHS_DIR, EEG_MODELING_DIR, \n",
    "    PREPOCHS_TRMD_EEG_F,\n",
    ")\n",
    "\n",
    "from udck19_utils import (\n",
    "    get_udck19_logger,\n",
    "    check_ENV,\n",
    "    N_EPOCH_SAMPS,  # epoch length in samples\n",
    "    N_TRMD_EEG_EPOCHS,  # number of epochs after EEG screening in pipeline_1\n",
    "    EEG_SCREEN_COL,  # HDF5 dataset key\n",
    "    EEG_EXPT_SPECS,\n",
    "    EEG_26_STREAMS,\n",
    "    RHS_VARS,\n",
    "    LMER_MODELS,\n",
    "    LMER_MODELS_BY_EXPT,\n",
    "    check_epochs_shape,\n",
    "    standardize,\n",
    "    fit_lmer_formulas,\n",
    "    udck19_figsave,\n",
    ")\n",
    "\n",
    "# enforce active conda env\n",
    "check_ENV()\n",
    "\n",
    "# logging config\n",
    "__file__ = 'udck19_pipeline_6.ipynb'\n",
    "logging.shutdown()\n",
    "\n",
    "LOGGER = get_udck19_logger(__file__)\n",
    "\n",
    "pipeline_start = datetime.datetime.now()\n",
    "\n",
    "LOGGER.info(f\"\"\"\n",
    "udck19_pipeline_6\n",
    "CONDA_DEFAULT_ENV: {os.environ['CONDA_DEFAULT_ENV']}\n",
    "pandas: {pd.__version__} \n",
    "fitgrid: {fitgrid.__version__}\n",
    "Start {pipeline_start.strftime(\"%d.%b %Y %H:%M:%S\")}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRERUN = False\n",
    "if PRERUN:\n",
    "    step = 5\n",
    "    time_slice = pd.IndexSlice[:, slice(-200, 600, step)]\n",
    "    LMER_CHANNELS = LMER_CHANNELS = ['MiPf', 'MiCe', 'MiPa', 'MiOc']\n",
    "    modl_path = EEG_MODELING_DIR / \"prerun\"\n",
    "    pfx = f'step{step}_chans{len(LMER_CHANNELS)}_'\n",
    "    N_CORES=21  # number of timepoints\n",
    "else:\n",
    "    time_slice = pd.IndexSlice[:, :]\n",
    "    LMER_CHANNELS = EEG_26_STREAMS\n",
    "    modl_path = EEG_MODELING_DIR \n",
    "    pfx = \"\"\n",
    "    N_CORES=24\n",
    "\n",
    "\n",
    "# for plots\n",
    "mpl.rcParams['figure.max_open_warning'] = 30\n",
    "style='seaborn-bright'\n",
    "plt.style.use(style)\n",
    "\n",
    "FIG_COUNT = 1\n",
    "FIG_PREFIX = 'udck19_pipeline_6_Fig'            \n",
    "\n",
    "# original fitted model summaries\n",
    "LMER_ACZ_RANEF_F = modl_path / f\"{pfx}lmer_acz_ranef.h5\"\n",
    "\n",
    "# for pipeline_6\n",
    "LMER_LURKING_F = modl_path / f\"{pfx}lmer_lurking.h5\"\n",
    "LMER_UNCORR_RANEF_F = modl_path / f\"{pfx}lmer_uncorr_ranef.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate normative cloze of non-indefinite articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../measures/udck19_norms_item_counts.yml\") as stream:\n",
    "    norms = yaml.load(stream.read(), Loader=yaml.SafeLoader)\n",
    "\n",
    "# select the article norm responses\n",
    "article_norms = [resp for resp in norms if \"_NA_NA_NA\" in resp[\"item_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute and merge proportion (cloze) of non-article continuations**\n",
    "\n",
    "Such as bare plurals, definite articles, adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def a_an_counter(item):\n",
    "    \n",
    "    expt_id = item['expt_id']\n",
    "    assert expt_id in [\"norm_1\", \"norm_3\", \"norm_6\"], f\"{expt_id} is not an article norming experiment\"\n",
    "    \n",
    "    item_id = item['item_id']\n",
    "    article_item_id = re.sub(r\"_NA_NA_NA\", \"\", item_id)\n",
    "    \n",
    "    orth = item[\"context_measures\"][\"orth\"]\n",
    "    modal_initial = orth[\"modal_initial\"]\n",
    "    n_resp = orth[\"n_responses\"]\n",
    "    n_NA = orth[\"n_NAs\"]\n",
    "    \n",
    "    initial_resp = item['orth'][0]\n",
    "    resp_tokens = initial_resp.keys()\n",
    "    n_a = initial_resp[\"a\"] if \"a\" in resp_tokens else 0\n",
    "    n_an = initial_resp[\"an\"] if \"an\" in resp_tokens else 0\n",
    "       \n",
    "    return expt_id, item_id, article_item_id, n_resp, n_a, n_an,n_NA\n",
    "\n",
    "art_counts = pd.DataFrame(\n",
    "    [a_an_counter(response) for response in article_norms], \n",
    "    columns = [\"expt\", \"item_id\", \"article_norm_id\", \"n_resp\", \"n_a\", \"n_an\",  \"n_NA\"]\n",
    ")\n",
    "\n",
    "art_counts[\"n_other\"] = art_counts[\"n_resp\"] - (art_counts[\"n_a\"] + art_counts[\"n_an\"])\n",
    "art_counts[\"other_cloze\"] = art_counts[\"n_other\"] / art_counts[\"n_resp\"]\n",
    "display(art_counts.shape)\n",
    "with pd.option_context(\"max_rows\", None):\n",
    "    display(art_counts.head())\n",
    "    display(art_counts.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "n, bins, patches = ax.hist(\n",
    "    art_counts[\"other_cloze\"], \n",
    "    bins=30, \n",
    "    weights = np.ones(len(art_counts)) / len(art_counts)\n",
    ")\n",
    "                                            \n",
    "ax.set_title(\"Non-indefinite articles cloze probability\")\n",
    "ax.set(\n",
    "    xlabel=\"Cloze Probability\",\n",
    "    ylabel=\"Density\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data\n",
    "\n",
    "* load epochs\n",
    "* merge the cloze of initial non-indefinite article words by item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update RHS_VARS for followup analysis\n",
    "ALT_RHS_VARS = RHS_VARS + [\"other_cloze_z\", \"article_cloze\", \"article_cloze_c\"]\n",
    "\n",
    "# load epochs prepared for analysis \n",
    "prepochs_trmd_eeg_df = pd.read_hdf(\n",
    "    PREPOCHS_TRMD_EEG_F, EEG_SCREEN_COL, mode='r'\n",
    ").reset_index().set_index([\"Epoch_idx\", \"Time\"])\n",
    "\n",
    "\n",
    "# sanity check single trial epochs as screened in pipeline_1\n",
    "assert (N_EPOCH_SAMPS, N_TRMD_EEG_EPOCHS) == check_epochs_shape(prepochs_trmd_eeg_df)\n",
    "assert all([val == 'accept' for val in prepochs_trmd_eeg_df[EEG_SCREEN_COL]])\n",
    "assert len(prepochs_trmd_eeg_df[\"article_item_id\"].unique()) == 794\n",
    "\n",
    "# index epochs for article norming and merge non-article initial word = \"other\" cloze values by item\n",
    "prepochs_trmd_eeg_df[\"article_norm_id\"] = prepochs_trmd_eeg_df[\"article_item_id\"].str.replace(r\"_a[_n]_.+\", \"\")\n",
    "prepochs_trmd_eeg_df = prepochs_trmd_eeg_df.join(\n",
    "    art_counts.set_index(\"article_norm_id\")[[\"other_cloze\"]], \n",
    "    how=\"left\", on=\"article_norm_id\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull together presented article,  non-indefinite article cloze by stim item\n",
    "art_other_cloze = (\n",
    "    prepochs_trmd_eeg_df\n",
    "    .query(\"Time==0\")[[\"article_item_id\", \"article_norm_id\", \"article_cloze\"]]\n",
    "    .reset_index(drop=True)\n",
    "    .drop_duplicates()\n",
    "    .join(\n",
    "        art_counts.set_index(\"article_norm_id\")[\"other_cloze\"], \n",
    "        how=\"left\", \n",
    "        on=\"article_norm_id\"\n",
    "    )\n",
    ")\n",
    "art_other_cloze.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "prepochs_trmd_eeg_df, prepochs_trmd_eeg_means_sds = standardize(\n",
    "    prepochs_trmd_eeg_df,\n",
    "    [\"article_cloze\", \"ART_noun_cloze\", \"NA_noun_cloze\", \"other_cloze\"]\n",
    ")\n",
    "\n",
    "# for conversion back\n",
    "ART_CLOZE_MN = prepochs_trmd_eeg_means_sds[\"article_cloze\"][\"mean\"]\n",
    "ART_CLOZE_SD = prepochs_trmd_eeg_means_sds[\"article_cloze\"][\"sd\"]\n",
    "\n",
    "# add centered article cloze, not scaled\n",
    "prepochs_trmd_eeg_df[\"article_cloze_c\"] = (\n",
    "    prepochs_trmd_eeg_df[\"article_cloze\"] -  prepochs_trmd_eeg_df[\"article_cloze\"].mean()\n",
    ")\n",
    "\n",
    "# sanity checks on data prep\n",
    "assert all(\n",
    "    col in prepochs_trmd_eeg_df.columns or col in prepochs_trmd_eeg_df.index.names\n",
    "    for col in EEG_26_STREAMS + ALT_RHS_VARS\n",
    ")\n",
    "\n",
    "assert set(prepochs_trmd_eeg_df.article_norm_id).issubset(art_counts.article_norm_id)\n",
    "assert not any(pd.isna(prepochs_trmd_eeg_df.article_cloze))\n",
    "assert not any(pd.isna(prepochs_trmd_eeg_df.other_cloze))\n",
    "\n",
    "# slice time-locking events from EEG samples\n",
    "events_df = prepochs_trmd_eeg_df.query(\"Time==0\").copy()\n",
    "prepochs_trmd_eeg_df.shape, events_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lurking variable: non-article cloze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation plotter\n",
    "def show_cloze_corr(col_1, col_2, data):\n",
    "    \n",
    "    x = data[col_1]\n",
    "    y = data[col_2]\n",
    "    \n",
    "    r, p = scipy.stats.pearsonr(x, y)\n",
    "    corr_res = f\"Pearson $r =$ {r:.3f}\\n$p =$ {p:.4e}\\n$r^2 =$ {r**2:0.3f}\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    title_str = f\"{col_1} x {col_2} correlation\"\n",
    "\n",
    "    ax.set_title(title_str, fontsize=14)\n",
    "    ax.set(\n",
    "        xlabel=f\"{col_1} (standardized)\", \n",
    "        ylabel=f\"{col_2} (standardized)\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        x=x, \n",
    "        y=y,\n",
    "        alpha=.025\n",
    "    );\n",
    "\n",
    "    ax.plot(x, x * r)\n",
    "\n",
    "    ax.annotate(\n",
    "        xy=(1.05, 0.75),\n",
    "        s=corr_res,\n",
    "        xycoords=\"axes fraction\",\n",
    "        fontsize=14,\n",
    "    );\n",
    "\n",
    "    return fig, ax, title_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## article and non-article correlation, covariance/variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcov_z = np.cov(events_df[\"article_cloze_z\"], events_df[\"other_cloze_z\"])\n",
    "a_s2 = vcov_z[0][0]\n",
    "o_s2 = vcov_z[1][1]\n",
    "ao_s12 = vcov_z[0][1]\n",
    "assert ao_s12 == vcov_z[1][0]\n",
    "\n",
    "# covariance/varianc ratio ... article other covar / article var\n",
    "C = ao_s12 / a_s2\n",
    "display(vcov_z)\n",
    "display(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax, title_str = show_cloze_corr(\"article_cloze_z\", \"other_cloze_z\", events_df);\n",
    "fig_tag = f\"{FIG_PREFIX} {FIG_COUNT} {title_str}\"\n",
    "FIG_COUNT = udck19_figsave(f, fig_tag, FIG_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* highly \"statistically significant\", i.e., vanishingly small $p$-value\n",
    "* **weakly correlated**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMER modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmer_fitter = functools.partial(\n",
    "    fgutil.summary.summarize,\n",
    "    modeler='lmer', \n",
    "    LHS=LMER_CHANNELS,\n",
    "    parallel=True, \n",
    "    n_cores=N_CORES,\n",
    "    REML=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs_fg = fitgrid.epochs_from_dataframe(\n",
    "    prepochs_trmd_eeg_df\n",
    "    .loc[time_slice, ALT_RHS_VARS + LMER_CHANNELS],  # prerun slicing, if any\n",
    "    epoch_id='Epoch_idx',\n",
    "    time='Time',\n",
    "    channels=LMER_CHANNELS\n",
    ")\n",
    "\n",
    "print(epochs_fg.table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative models\n",
    "LMER_ALT = {\n",
    "    \"lmer_lurking\": [\n",
    "        \n",
    "        # 0. KIM w/ confound\n",
    "        (\n",
    "            \" article_cloze_z + other_cloze_z + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze_z | sub_id) + \"\n",
    "            \"(1 | article_item_id)\"\n",
    "        ),\n",
    "\n",
    "        # 1. drop other\n",
    "        (\n",
    "            \" article_cloze_z + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze_z | sub_id) + \"\n",
    "            \"(1 | article_item_id)\"\n",
    "        ),\n",
    "       \n",
    "        # 2. drop article\n",
    "        (\n",
    "            \"other_cloze_z + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze_z | sub_id) + \"\n",
    "            \"(1 | article_item_id)\"\n",
    "        ),\n",
    " \n",
    "        # 3. drop article, other\n",
    "        (\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze_z | sub_id) + \"\n",
    "            \"(1 | article_item_id)\"\n",
    "        ),\n",
    "        \n",
    "        \n",
    "        # 4. 5. other as-if KIM\n",
    "        \"other_cloze_z + (1 | expt) + (other_cloze_z | sub_id) + (1| article_item_id)\",\n",
    "        \"(1 | expt) + (other_cloze_z | sub_id) + (1| article_item_id)\",\n",
    "\n",
    "        # 6. 7. other as-if KIP\n",
    "        \"other_cloze_z + (1 | expt) + (1 | sub_id) + (1| article_item_id)\",\n",
    "        \"(1 | expt) + (1 | sub_id) + (1| article_item_id)\",\n",
    "        \n",
    "    ],\n",
    " \n",
    "    \"lmer_uncorr_ranef\": [\n",
    "\n",
    "        # maximal ranefs w/ uncorrelated intercepts and slopes\n",
    "        # with article cloze, centered, scaled\n",
    "\n",
    "        # 0. cloze MAX_uncor \n",
    "        (\n",
    "            \" article_cloze + \"\n",
    "            \"(article_cloze || expt) + \"\n",
    "            \"(article_cloze || sub_id) + \"\n",
    "            \"(article_cloze || item_id)\"\n",
    "        ),\n",
    "\n",
    "        # 1. centered cloze MAX_uncor\n",
    "        (\n",
    "            \" article_cloze_c + \"\n",
    "            \"(article_cloze_c || expt) + \"\n",
    "            \"(article_cloze_c || sub_id) + \"\n",
    "            \"(article_cloze_c || item_id)\"\n",
    "        ),\n",
    "\n",
    "        # 2. standardized cloze MAX_uncor\n",
    "        (\n",
    "            \" article_cloze_z + \"\n",
    "            \"(article_cloze_z || expt) + \"\n",
    "            \"(article_cloze_z || sub_id) + \"\n",
    "            \"(article_cloze_z || item_id)\"\n",
    "        ),\n",
    "        \n",
    "        # KIM ranefs with article cloze, centered and scaled\n",
    "        \n",
    "        # 3. cloze KIM\n",
    "        (\n",
    "            \" article_cloze + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze || sub_id) + \"\n",
    "            \"(1 | item_id)\"\n",
    "        ),\n",
    "\n",
    "        # 4. centered cloze KIM\n",
    "        (\n",
    "            \" article_cloze_c + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze_c || sub_id) + \"\n",
    "            \"(1 | item_id)\"\n",
    "        ),\n",
    "\n",
    "        # 5. standaradized cloze KIM\n",
    "        (\n",
    "            \" article_cloze_z + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze_z || sub_id) + \"\n",
    "            \"(1 | item_id)\"\n",
    "        ),\n",
    "        \n",
    "        # 6. cloze KIM\n",
    "        (\n",
    "            \" article_cloze + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze | sub_id) + \"\n",
    "            \"(1 | item_id)\"\n",
    "        ),\n",
    "\n",
    "        # 7. centered cloze KIM\n",
    "        (\n",
    "            \" article_cloze_c + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze_c | sub_id) + \"\n",
    "            \"(1 | item_id)\"\n",
    "        ),\n",
    "\n",
    "        # 8. standardized cloze KIM (easier to recompute than merge summaries)\n",
    "        (\n",
    "            \" article_cloze_z + \"\n",
    "            \"(1 | expt) + \"\n",
    "            \"(article_cloze_z | sub_id) + \"\n",
    "            \"(1 | item_id)\"\n",
    "        ),\n",
    "  \n",
    "        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "LOGGER.info(f\"Start modeling: {start_time.strftime('%d.%b %Y %H:%M:%S')}\")\n",
    "            \n",
    "for model_set in LMER_ALT.keys():\n",
    "    LOGGER.info(f\"\"\"{model_set}\"\"\")\n",
    "    print(model_set)\n",
    "            \n",
    "            \n",
    "\n",
    "    # supress pandas FutureWarning for rpy2 DataFrame.from_items\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\") \n",
    "        fit_lmer_formulas(\n",
    "            epochs_fg,\n",
    "            lmer_fitter,\n",
    "            LMER_ALT[model_set],\n",
    "            modl_path / (pfx + model_set + \".h5\"),\n",
    "            LOGGER\n",
    "        )\n",
    "\n",
    "elapsed = datetime.datetime.now() - start_time\n",
    "LOGGER.info(f\"Elapsed time modeling: {elapsed}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot pchan params per beta\n",
    "beta_kws = {\n",
    "    \"(Intercept)\": {\n",
    "        'margins': {'bottom': 0.15}, \n",
    "        'axes': {\"ylim\": (-4, 4)},  # these scale y-extent of the waveforms\n",
    "        'cal': {\n",
    "            'ylabel': \"$\\mu V$\",\n",
    "            'yticks': (-2, 2),\n",
    "        },        \n",
    "        'chan_label': 'north',\n",
    "    },\n",
    "    \n",
    "    \"article_cloze_z\": {\n",
    "        'margins': {'bottom': 0.15}, \n",
    "        'axes': {\"ylim\": (-.25, 0.75)},\n",
    "        'cal': {\n",
    "            'ylabel': \"$\\mu V / SD_{article\\_cloze}$\",\n",
    "            'yticks': (0, .5),\n",
    "        },\n",
    "        'chan_label': 'north'\n",
    "\n",
    "        \n",
    "    },\n",
    "    \n",
    "    \"other_cloze_z\": {\n",
    "        'margins': {'bottom': 0.15}, \n",
    "        'axes': {\"ylim\": (-.25, 0.75)},\n",
    "        'cal': {\n",
    "            'ylabel': \"$\\mu V / SD_{article\\_cloze}$\",\n",
    "            'yticks': (0, .5),\n",
    "        },\n",
    "        'chan_label': 'north'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRERUN:\n",
    "    layout = MPL_MIDLINE\n",
    "    for beta, kws in beta_kws.items():\n",
    "        kws.update({'chan_label': 'east'})\n",
    "else:\n",
    "    layout = MPL_32_CHAN\n",
    "\n",
    "\n",
    "# highlight ... alpha=0 to disable\n",
    "n4_highlight = {\n",
    "    'xmin': 300,\n",
    "    'xmax': 500,\n",
    "    'color': 'magenta',\n",
    "    'alpha': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert LMER_LURKING_F.exists()\n",
    "assert LMER_ACZ_RANEF_F.exists()\n",
    "assert LMER_UNCORR_RANEF_F.exists()\n",
    "\n",
    "LOGGER.info(f\"\"\"\n",
    "Plotting fitted models from : {LMER_LURKING_F, LMER_ACZ_RANEF_F, LMER_UNCORR_RANEF_F}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AIC model comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model sets for AIC comparison\n",
    "ALT_LMER_COMPS = {\n",
    "    # lurking variable comparisons\n",
    "    \"article_other_stack\": (LMER_LURKING_F, LMER_ALT[\"lmer_lurking\"][0:4]),  # stack\n",
    "    \"other_KIM_comp\": (LMER_LURKING_F, LMER_ALT[\"lmer_lurking\"][4:6]), # KIM pair\n",
    "    \"other_KIP_comp\": (LMER_LURKING_F, LMER_ALT[\"lmer_lurking\"][6:8]), # KIP pair\n",
    "    \n",
    "    # article cloze on 3 scales w/ corr_KIM = w/ KIM ranefs\n",
    "    \"uncorr_MAX\": (LMER_UNCORR_RANEF_F, LMER_ALT[\"lmer_uncorr_ranef\"][0:3]),\n",
    "    \"uncorr_KIM\": (LMER_UNCORR_RANEF_F, LMER_ALT[\"lmer_uncorr_ranef\"][3:6]), \n",
    "    \"corr_KIM\": (LMER_UNCORR_RANEF_F, LMER_ALT[\"lmer_uncorr_ranef\"][6:9]), \n",
    "}\n",
    "LOGGER.info(\n",
    "    f\"Alternative model AIC comparisons\\n{ALT_LMER_COMPS}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x0, x1 in [(-1500, 1500), (-200, 600)]:\n",
    "\n",
    "    for comptag, (rerp_file, comp) in ALT_LMER_COMPS.items():\n",
    "        print(comptag, comp)\n",
    "        try:\n",
    "            f, axs = fgutil.summary.plot_AICmin_deltas(\n",
    "                read_fg_summaries_hdf(rerp_file, comp).query(\"Time >= @x0 and Time <= @x1\")\n",
    "            )\n",
    "        except:\n",
    "            print(\"bad group: \", comptag, comp, \"\\n\")\n",
    "            raise\n",
    "\n",
    "        f.set_size_inches(16, int(5 * len(axs)))\n",
    "        fig_tag = f\"{FIG_PREFIX} {FIG_COUNT} {comptag} AIC {x0} {x1}\"\n",
    "        n_rows, n_cols = axs.shape\n",
    "        for row in range(n_rows):\n",
    "            ax = axs[row, 0]\n",
    "            \n",
    "            # instead of fig.suptitle\n",
    "            if row == 0:\n",
    "                ax.text(\n",
    "                    s=fig_tag,\n",
    "                    x=0,\n",
    "                    y=1.15,\n",
    "                    fontsize='x-large',\n",
    "                    fontweight='bold',\n",
    "                    ha=\"left\",\n",
    "                    va=\"bottom\",\n",
    "                    transform=ax.transAxes\n",
    "                ) \n",
    "\n",
    "            # panel label    \n",
    "            ax.text(\n",
    "                x=-0.1,\n",
    "                y=1.0,\n",
    "                s=f\"{panel_from_idx(row)})\", \n",
    "                horizontalalignment='right',\n",
    "                fontsize='x-large',\n",
    "                fontweight='bold',\n",
    "                transform=ax.transAxes\n",
    "            )\n",
    "            \n",
    "            for axj in [0,1]:\n",
    "                axs[row, axj].axvspan(**n4_highlight)\n",
    "\n",
    "            ax.set(ylim=(0,25))\n",
    "            if ax.get_legend():\n",
    "                ax.get_legend().remove()\n",
    "            if row == n_rows - 1:\n",
    "                ax.legend(loc='upper left', bbox_to_anchor=(0, -0.1), ncol=4)\n",
    "        FIG_COUNT = udck19_figsave(f, fig_tag, FIG_COUNT)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lurking variable lmerERPs: non-article cloze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure C is correct\n",
    "assert np.isclose(C, -0.26445942781151827)\n",
    "\n",
    "LMER_LURKING_MODELS = {\n",
    "    \"other_KIM\": (LMER_LURKING_F, LMER_ALT[\"lmer_lurking\"][4]), \n",
    "    \"other_KIM_bias\": (LMER_LURKING_F, LMER_ALT[\"lmer_lurking\"][4]), \n",
    "\n",
    "    \"other_KIP\": (LMER_LURKING_F, LMER_ALT[\"lmer_lurking\"][6]),\n",
    "    \"other_KIP_bias\": (LMER_LURKING_F, LMER_ALT[\"lmer_lurking\"][6]),\n",
    "\n",
    "    \"article_KIM\": (LMER_ACZ_RANEF_F, LMER_MODELS[\"lmer_acz_ranef\"][5]), \n",
    "    \"article_KIM_spurious\": (LMER_ACZ_RANEF_F, LMER_MODELS[\"lmer_acz_ranef\"][5]), \n",
    "\n",
    "    \"article_KIP\": (LMER_ACZ_RANEF_F, LMER_MODELS[\"lmer_acz_ranef\"][7]), \n",
    "    \"article_KIP_spurious\": (LMER_ACZ_RANEF_F, LMER_MODELS[\"lmer_acz_ranef\"][7]), \n",
    "\n",
    "    \"article_other_KIM\": (LMER_LURKING_F, LMER_ALT[\"lmer_lurking\"][0]), \n",
    "}\n",
    "\n",
    "LOGGER.info(f\"lmerERPs for {LMER_LURKING_MODELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intervals = [(-1500, 1500), (-200, 600)]\n",
    "for x0, x1 in intervals:\n",
    "    \n",
    "    for mtag, (rerp_file, model) in LMER_LURKING_MODELS.items():\n",
    "        print(mtag, model)\n",
    "\n",
    "        rerps = read_fg_summaries_hdf(\n",
    "                rerp_file, [model],\n",
    "            ).query('Time >= @x0 and Time <= @x1')\n",
    "        \n",
    "        # plot bias for non-article cloze KIM and KIP \n",
    "        if \"bias\" in mtag or \"spurious\" in mtag:\n",
    "            est_rerps = None\n",
    "            \n",
    "            si = pd.IndexSlice\n",
    "            if \"bias\" in mtag:\n",
    "                # estimate bias of non-article cloze\n",
    "                rerps = rerps.query(\"beta == 'other_cloze_z'\")\n",
    "                rerp_betas = rerps.loc[si[:, :, \"other_cloze_z\", \"Estimate\"], :]\n",
    "                est_rerps = rerp_betas * C\n",
    "            elif \"spurious\" in mtag:\n",
    "                # if article cloze is spurious B2 what caused it\n",
    "                rerps = rerps.query(\"beta == 'article_cloze_z'\")\n",
    "                rerp_betas = rerps.loc[si[:, :, \"article_cloze_z\", \"Estimate\"], :]\n",
    "                est_rerps = rerp_betas / C\n",
    "            else:\n",
    "                raise ValueError(f\"unknown mtag: {mtag}\")\n",
    "            \n",
    "            # set the values\n",
    "            for key in [\"Estimate\", \"2.5_ci\", \"97.5_ci\"]:\n",
    "                rerps.loc[pd.IndexSlice[:, :, :, key], :] = est_rerps\n",
    "                \n",
    "        plots = plotchans(rerps, beta_kws, style=style, layout=layout, se_ci=\"CI\")\n",
    "        for plot in plots:\n",
    "\n",
    "            beta = plot['beta']\n",
    "            f = plot['fig']\n",
    "            for ax in f.get_axes():\n",
    "                ax.axvspan(**n4_highlight)\n",
    "                \n",
    "                # atrocious hack\n",
    "                if \"other\" in beta:\n",
    "                    ax.set(ylabel=ax.get_ylabel().replace(\"article\", \"other\"))\n",
    "\n",
    "            fig_tag = f\"{FIG_PREFIX}_{FIG_COUNT}_{mtag}_{beta}_{x0}_{x1}\"\n",
    "            suptitle_txt = f._suptitle.get_text()\n",
    "            x, y = f._suptitle.get_position()\n",
    "            f.suptitle(\n",
    "                f\"{FIG_PREFIX} {FIG_COUNT}\\n{mtag} {suptitle_txt}\",\n",
    "                x=x,\n",
    "                y=y,\n",
    "                fontsize='x-large',\n",
    "                fontweight='bold',\n",
    "                ha=\"left\",\n",
    "                va=\"bottom\",\n",
    " \n",
    "            )\n",
    "            FIG_COUNT = udck19_figsave(\n",
    "                f,\n",
    "                f\"{FIG_PREFIX}_{FIG_COUNT}_{mtag}_{beta}_{x0}_{x1}\", \n",
    "                FIG_COUNT\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncorrelated random intercepts and slopes\n",
    "\n",
    "Appropo the \"subtle drawback\" of dropping correlated intercepts and slopes \n",
    "\n",
    "> \"Models in which the slopes and intercepts are allowed to have a nonzero correlation (e.g., fm1) are invariant to additive shifts of the continuous predictor (Days in this case). This invariance breaks down when the correlation is constrained to zero; any shift in the predictor will necessarily lead to a change in the estimated correlation, and in the likelihood and predictions of the model.\" (Bates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting Linear Mixed-Effects Models Using lme4. 2015, 67(1), 48. doi:10.18637/jss.v067.i01, p. 9).\n",
    "\n",
    "\n",
    "Compare article cloze (range 0 - 1), centered article cloze (mean = 0), standardized article cloze for\n",
    "\n",
    "* Maximal model except for dropping experiment, subject, item correlated random intercepts and slope\n",
    "\n",
    "* KIM except dropping correlated random intercepts and slopes\n",
    "\n",
    "* KIM as originally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_plots(mtag, df, fixeffs, keys, chans, models, fig_count):\n",
    "    \n",
    "    # rescale article_cloze_z back to uV\n",
    "    if \"article_cloze_z\" in df.index.unique(\"beta\"):\n",
    "        article_cloze_est_uv = (\n",
    "            df.query(\"key=='Estimate' and beta=='article_cloze_z'\") / ART_CLOZE_SD\n",
    "        )\n",
    "        article_cloze_est_uv.reset_index('key', inplace=True)\n",
    "        article_cloze_est_uv[\"key\"] = \"Estimate_uv\"\n",
    "        article_cloze_est_uv.set_index(\"key\", append=True, inplace=True)\n",
    "        df = pd.concat([df, article_cloze_est_uv])\n",
    "\n",
    "    fig_tag = f\"{FIG_PREFIX}_{fig_count}_{mtag}\"\n",
    "    f, axs = plt.subplots(len(keys), len(chans), figsize=(16, 3*len(keys)), sharey='row')\n",
    "    for ki, key in enumerate(keys):\n",
    "\n",
    "        data = df.query(\"key == @key and beta in @fixeffs\")\n",
    "        warns = df.query(\"key == 'has_warning' and beta in @fixeffs\")\n",
    "        \n",
    "        # hack for rescaled article_cloze_z \n",
    "        if key == \"Estimate\":\n",
    "            est_uv = df.query(\"key=='Estimate_uv' and beta=='article_cloze_z'\")\n",
    "        else:\n",
    "            est_uv = None\n",
    " \n",
    "        for ci, chan in enumerate(chans):\n",
    "            #print(axs.shape)\n",
    "            ax = axs[ki, ci]\n",
    "            #ax.plot(data.Time.unique(), ptschan, ax=ax)\n",
    "            for mi, model in enumerate(data.index.unique(\"model\")):\n",
    "\n",
    "                model_data = data.reset_index(\"Time\").query(\"model == @model\")\n",
    "                warnings_data = warns.reset_index(\"Time\").query(\"model==@model\")\n",
    "            \n",
    "                times = model_data[\"Time\"]\n",
    "                pts = model_data[chan]\n",
    "                # data transforms\n",
    "                if key in [\"P-val\", \"DF\"]:\n",
    "                    pts = np.log10(pts)\n",
    "                    ylabel = f\"log10({key})\"\n",
    "                else:\n",
    "                    ylabel = key\n",
    "                \n",
    "                ax.plot(times, pts, label=model) # .split()[0])\n",
    "                \n",
    "                # warnings\n",
    "                warn_pts = [\n",
    "                    (times[i], pts[i]) for i, pt, in enumerate(warnings_data[chan]) if pt == 1.0\n",
    "                ]\n",
    "                for t, wpt in warn_pts:\n",
    "                    ax.plot(t, wpt, lw=0, marker='o', color='red')\n",
    " \n",
    "                # cloze back on uV scale\n",
    "                if est_uv is not None:\n",
    "                    ax.plot(times, est_uv[chan], color='red', lw=0, marker=\"+\")\n",
    "            \n",
    "\n",
    "                #model_data.plot(x=\"Time\", y=chan, ax=ax, label=model.split()[0])\n",
    "  \n",
    "            # left column gets key label\n",
    "            if ci == 0:\n",
    "                ax.set(ylabel=f\"{ylabel}\")\n",
    "\n",
    "            # bottom row gets channel\n",
    "            if ki == len(keys)-1:\n",
    "                ax.set(xlabel=chan)\n",
    "\n",
    "            # first row, col triggers title and legend\n",
    "            if ki == 0 and ci == 0:\n",
    "                ax.margins(y=.5)\n",
    "                leg = ax.legend(loc=(0, 1.025)) #\"upper left\")\n",
    "                leg.set_in_layout(False)\n",
    "                f.suptitle(\n",
    "                    t=fig_tag,\n",
    "                    x=0.1, y=.95,\n",
    "                    fontsize='x-large',\n",
    "                    fontweight='bold',\n",
    "                    ha=\"left\",\n",
    "                    va=\"bottom\",\n",
    "                )\n",
    " \n",
    "    fig_count = udck19_figsave(f, fig_tag, fig_count)\n",
    "    return fig_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fixeffs = [\"article_cloze_z\", \"article_cloze\", \"article_cloze_c\"]\n",
    "keys = [\"Estimate\", \"SE\", \"T-stat\", \"P-val\", \"DF\"]\n",
    "chans = [\"MiPf\", \"MiCe\", \"MiPa\", \"MiOc\"]\n",
    "\n",
    "for mtag in [\"uncorr_MAX\", \"uncorr_KIM\", \"corr_KIM\"]:\n",
    "    rerp_file, models = ALT_LMER_COMPS[mtag]\n",
    "    print(rerp_file, models)\n",
    "    \n",
    "    rerps = read_fg_summaries_hdf(\n",
    "                rerp_file, models\n",
    "            )#.query('Time >= @x0 and Time <= @x1')\n",
    "\n",
    "    FIG_COUNT = key_plots(mtag, rerps, fixeffs, keys, chans, models, FIG_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log execution time\n",
    "pipeline_stop = datetime.datetime.now()\n",
    "\n",
    "elapsed =  pipeline_stop - pipeline_start\n",
    "LOGGER.info(f\"\"\"\n",
    "Done {pipeline_stop.strftime(\"%d.%b %Y %H:%M:%S\")}\n",
    "Elapsed time: {elapsed}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
